# Overconfidence

# The Illusion of Understanding

*Narrative Fallacy* - flawed stories of our past shape our views of the future. E.x., before sabernetics in baseball, people would overindex on archetypes they match people to.

*Halo effect* is related people who look good do good things, etc. Doesn't account for the fact that people behave in a multitude of ways.

What you see is all there is. E.g., Google, talented dropouts making a great company, but you only see the winners.

Another example of narrative fallacy:
* Ask people what the probabilities for outcomes of Nixon's visit to China would be before and after the actual event.
* People's probabilities shift to reality. This may get in the way of counterfactual analysis and growth.

*Outcome bias* is a form of narrative fallacy. People don't pay as much attention to when you do do your job versus when you don't. 

# The Illusion of Validity

*Confidence-by-coherence*. Jumping to conclusions with little evidence only because they fit together nicely.

E.x. Israeli defense force exercise with no structure to see who steps up for leadership positions was not meaningfully better at predicting future performance than random guessing.

*Illusion of skill*. Financial market industry has lots of investors who claim skill, but if they had skill, then their YoY performance ranking would be stable. 

Persistent achievement is evidence of skill.

# Intuition vs Formulas

Clinical predictions based on qualitative assessment from trained professionals versus using the formula for predicting

* high school grades
* wine quality
* baby weights for assessing when the baby is healthy. APGAR score.

The algorithms win even if they're simple. In low validity scenarios, difficult to maintain consistency.

People don't like adopting checklists.

# Expert Intuition: When can We Trust It?

Need an environment that is sufficient regular to be predictable and an opportunity to learn the regularities through prolonged practice.

Positive example. Chess and poker. Well-defined rules and statistics and can play lots of times

Positive example. Sports. Well-defined physics.

Negative example. Stock pickers, long-term forecasters. They're in a zero-validity environment with little environmental feedback and infrequent feedback opportunities.

"Wicked environments" has a systematic bias from the feedback-gathering process itself (e.g., doctors who wanted to evaluate whether a patient had typhoid would do so by touching their patient's tongues before they had a good model for the transmission of diseases, but this just proved them right by infecting the patients that they were contacting).

# The Outside View

Personal example where the author was writing a book with a friend experienced in writing books. He asked what the probability of the book being finished in two years was, given the situation. The friend answered 2 years. But what is the probability of failure in the past for other people? It would take them 7 years.

Sunk-cost, over-optimism / hopefulness from the situation, and thinking about only the positive outcomes. Outside view gives a fair evaluation of what the outcome distribution looks like.

Induces the *planning fallacy*, which is the above-described situation. 2005 study on rail projects confirms the above systematic error.

How to avoid the planning fallacy:

* Identify an appropriate reference class
* Obtain statistics for the reference class
* Use specific information about the case to adjust the reference class completion anchor.

# The Engine of Capitalism

*Illusion of control*. 90% of drivers think they are better than average, but that's just hubris.

Financial officers (CFO) of corporations don't have a good sense of the future of the stock market. They couldn't predict its performance. Using confidence intervals would be more accurate but it'd be a confession of ignorance, which people don't want to do.
